from fastapi import APIRouter, Depends, Header, HTTPException, status, UploadFile, File, Form, Request

from sqlalchemy.orm import Session

from typing import Dict, Any, Optional

from pydantic import BaseModel

from datetime import datetime

import requests

import os



from app.database import get_db

from app.db import queries

from app.middleware.auth import get_tgid_from_header

from app.config import settings

from app.utils.pdf_extractor import extract_text_from_pdf

import traceback



router = APIRouter()



# Test endpoint to verify routing works

@router.get("/test")

async def test_endpoint():

    return {"message": "API router is working", "status": "ok"}



# Test endpoint for upload-file (no auth, no file)

@router.post("/upload-file-test")

async def upload_file_test():

    print("=" * 50)

    print("UPLOAD FILE TEST ENDPOINT CALLED")

    print("=" * 50)

    return {"message": "Upload file endpoint is accessible", "status": "ok"}





# Request models

class UpdateProfileRequest(BaseModel):

    profile: Dict[str, Any]





class UpdateAnalysesRequest(BaseModel):

    analyses: Dict[str, Any]





class UpdateRecommendationsRequest(BaseModel):

    recommendations: Dict[str, Any]


class UpdateOprosAnemiaRequest(BaseModel):
    opros_anemia: Dict[str, Any]





class NotifyUploadRequest(BaseModel):

    fileName: str

    mime: str

    size: int




class GetRecommendationRequest(BaseModel):
    analysis_id: str


class GetRecommendationByTextRequest(BaseModel):
    analysis_text: Optional[str] = None
    analysis_id: Optional[str] = None


class RecommendationResultRequest(BaseModel):
    tgid: str
    analysis_id: str
    recommendation: str



# GET /api/analyses/history - Get all analyses history from allanalize column

@router.get("/analyses/history")

async def get_analyses_history(

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    """Get all analyses history from allanalize column"""

    user = queries.get_or_create_user(db, tgid)

    all_analyses = user.allanalize or {}

    
    
    # Return as list if it's a list, or wrap in object if it's a dict

    if isinstance(all_analyses, list):

        return {"analyses": all_analyses}

    elif isinstance(all_analyses, dict):

        # If it's a dict, try to extract list from common keys

        if "analyses" in all_analyses:

            return {"analyses": all_analyses["analyses"]}

        elif "history" in all_analyses:

            return {"analyses": all_analyses["history"]}

        else:

            # Convert dict to list of items

            return {"analyses": [all_analyses] if all_analyses else []}

    else:

        return {"analyses": []}


# GET /api/opros/history - Get questionnaires history from opros_anemia column

@router.get("/opros/history")

async def get_opros_history(

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    """Get questionnaires history from opros_anemia column"""

    user = queries.get_or_create_user(db, tgid)

    opros_data = user.opros_anemia or {}

    

    # Return the opros_anemia data

    return {"opros": opros_data}





# GET /api/me - Get or create user

@router.get("/me")

async def get_me(

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    user = queries.get_or_create_user(db, tgid)

    
    
    # –Ø–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º

    db.refresh(user)

    
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

    print(f"[get_me] User {tgid} - analyses type: {type(user.analyses)}")

    print(f"[get_me] User {tgid} - analyses value: {user.analyses}")

    if user.analyses:

        print(f"[get_me] User {tgid} - analyses keys: {list(user.analyses.keys()) if isinstance(user.analyses, dict) else 'not a dict'}")

        if isinstance(user.analyses, dict) and "last_report" in user.analyses:

            print(f"[get_me] User {tgid} - last_report: {user.analyses['last_report']}")

            if isinstance(user.analyses["last_report"], dict):

                print(f"[get_me] User {tgid} - last_report keys: {list(user.analyses['last_report'].keys())}")

                print(f"[get_me] User {tgid} - last_report.text exists: {'text' in user.analyses['last_report']}")

                if "text" in user.analyses["last_report"]:

                    text_value = user.analyses["last_report"]["text"]

                    print(f"[get_me] User {tgid} - last_report.text type: {type(text_value)}")

                    print(f"[get_me] User {tgid} - last_report.text length: {len(text_value) if isinstance(text_value, str) else 'not a string'}")
    
    

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

    analyses_data = user.analyses if user.analyses is not None else {}

    # –ï—Å–ª–∏ analyses —ç—Ç–æ –Ω–µ dict, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å

    if not isinstance(analyses_data, dict):

        print(f"[get_me] WARNING: analyses is not a dict, type: {type(analyses_data)}, value: {analyses_data}")

        analyses_data = {}
    
    

    return {

        "tgid": user.tgid,

        "profile": user.profile or {},

        "analyses": analyses_data

    }





# POST /api/me - Update profile

@router.post("/me")

async def update_profile(

    request: UpdateProfileRequest,

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    # Log incoming profile data

    print(f"=== UPDATE PROFILE REQUEST ===")

    print(f"TGID: {tgid}")

    print(f"Received profile data: {request.profile}")

    print(f"Profile data type: {type(request.profile)}")

    print(f"Profile keys: {list(request.profile.keys())}")

    for key, value in request.profile.items():

        print(f"  {key}: {value} (type: {type(value)})")
    
    

    # Update profile (this function already handles getting/creating user)

    user = queries.update_profile(db, tgid, request.profile)

    
    
    # Log updated profile

    print(f"Profile after update: {user.profile}")

    print(f"Profile type after update: {type(user.profile)}")

    print(f"Profile keys after update: {list(user.profile.keys()) if user.profile else 'None'}")

    if user.profile:

        for key, value in user.profile.items():

            print(f"  {key}: {value} (type: {type(value)})")

    print(f"===============================")

    
    
    return {

        "tgid": user.tgid,

        "profile": user.profile or {}

    }





# POST /api/analyses/summary - Update analyses

@router.post("/analyses/summary")

async def update_analyses(

    request: UpdateAnalysesRequest,

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    user = queries.update_analyses(db, tgid, request.analyses)

    return {

        "analyses": user.analyses or {}

    }





# POST /api/reco/basic - Update recommendations

@router.post("/reco/basic")

async def update_recommendations(

    request: UpdateRecommendationsRequest,

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    user = queries.update_recommendations(db, tgid, request.recommendations)

    return {

        "recommendations": user.recommendations or {}

    }


# POST /api/opros/anemia - Update iron deficiency questionnaire

@router.post("/opros/anemia")

async def update_opros_anemia(

    request: UpdateOprosAnemiaRequest,

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    user = queries.update_opros_anemia(db, tgid, request.opros_anemia)

    return {

        "opros_anemia": user.opros_anemia or {}

    }


# POST /api/recommendations/get - Get recommendation by sending analysis text to webhook
@router.post("/recommendations/get")
async def get_recommendation(
    request: GetRecommendationByTextRequest,
    tgid: str = Depends(get_tgid_from_header),
    db: Session = Depends(get_db)
):
    """Get recommendation by sending analysis text to AI webhook.
    If analysis_text is not provided, will get all analyses from database and combine them.
    """
    webhook_url = settings.RECOMMENDATIONS_WEBHOOK_URL
    
    if not webhook_url:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Recommendations webhook URL not configured"
        )
    
    user = queries.get_or_create_user(db, tgid)
    
    # If analysis_text is not provided, get all analyses from database
    if not request.analysis_text:
        # Get all analyses from allanalize
        all_analyses = user.allanalize or {}
        analyses_list = []
        
        # Handle different allanalize formats
        if isinstance(all_analyses, list):
            analyses_list = all_analyses
        elif isinstance(all_analyses, dict):
            if "analyses" in all_analyses and isinstance(all_analyses["analyses"], list):
                analyses_list = all_analyses["analyses"]
            elif "history" in all_analyses and isinstance(all_analyses["history"], list):
                analyses_list = all_analyses["history"]
        
        # Combine all analysis texts
        analysis_texts = []
        for analysis in analyses_list:
            if isinstance(analysis, dict):
                text = analysis.get("text") or analysis.get("report") or ""
                if text and text.strip():
                    # Add separator with analysis info
                    file_name = analysis.get("fileName") or analysis.get("file_name") or "–ê–Ω–∞–ª–∏–∑"
                    created_at = analysis.get("createdAt") or analysis.get("created_at") or ""
                    analysis_texts.append(f"\n\n=== {file_name} {created_at} ===\n{text}")
        
        if not analysis_texts:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞–Ω–∞–ª–∏–∑—ã, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
            )
        
        combined_analysis_text = "\n".join(analysis_texts)
        # Use fixed analysis_id for all analyses to allow saving and loading recommendations
        analysis_id = request.analysis_id or f"all_analyses_{tgid}"
    else:
        combined_analysis_text = request.analysis_text
        analysis_id = request.analysis_id or f"analysis_{tgid}_{int(datetime.utcnow().timestamp())}"
    
    # Check if recommendation exists in rekom
    rekom_data = user.rekom or {}
    
    # Check if recommendation already exists in rekom
    if isinstance(rekom_data, dict) and analysis_id in rekom_data:
        return {
            "analysis_id": analysis_id,
            "recommendation": rekom_data[analysis_id],
            "cached": True
        }
    
    # Get user profile data
    profile = user.profile or {}
    
    # Send analysis text to webhook with profile data (webhook will send result back via HTTP Request)
    try:
        webhook_payload = {
            "tgid": tgid,
            "analysis_text": combined_analysis_text,
            "analysis_id": analysis_id,
            "profile": {
                "height": profile.get("height"),
                "weight": profile.get("weight"),
                "gender": profile.get("gender"),
                "age": profile.get("age")
            }
        }
        
        print(f"Sending analysis text to recommendations webhook: {webhook_url}")
        print(f"Analysis text length: {len(combined_analysis_text)} characters")
        print(f"Webhook will send result back via HTTP Request to /api/recommendations/result")
        
        # Send to webhook (don't wait for response - webhook will send result via HTTP Request)
        try:
            requests.post(
                webhook_url,
                json=webhook_payload,
                headers={"Content-Type": "application/json"},
                timeout=10  # Short timeout just to send the request
            )
        except Exception as e:
            print(f"Warning: Could not send to webhook: {e}")
            # Continue anyway - webhook might still process
        
        # Return status - recommendation will be saved in rekom by webhook
        return {
            "analysis_id": analysis_id,
            "status": "processing",
            "message": "Analysis sent to AI for processing. Please wait..."
        }
            
    except Exception as e:
        print(f"Error sending to webhook: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error sending to webhook: {str(e)}"
        )


# POST /api/recommendations/result - Receive recommendation result from webhook (no auth required)
@router.post("/recommendations/result")
async def receive_recommendation_result(
    request: RecommendationResultRequest,
    db: Session = Depends(get_db)
):
    """Receive recommendation result from webhook and save to rekom column
    
    This endpoint is called by n8n webhook via HTTP Request to send back
    the AI-generated recommendation.
    
    Expected JSON body:
    {
        "tgid": "747737181",
        "analysis_id": "analysis_123",
        "recommendation": "—Ç–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏..."
    }
    """
    print(f"=== Receiving recommendation result from webhook ===")
    print(f"TGID: {request.tgid}")
    print(f"Analysis ID: {request.analysis_id}")
    print(f"Recommendation length: {len(request.recommendation)} characters")
    
    try:
        # Get or create user
        user = queries.get_or_create_user(db, request.tgid)
        rekom_data = user.rekom or {}
        
        # Save recommendation to rekom column
        if not isinstance(rekom_data, dict):
            rekom_data = {}
        rekom_data[request.analysis_id] = request.recommendation
        user.rekom = rekom_data
        from sqlalchemy.orm.attributes import flag_modified
        flag_modified(user, "rekom")
        
        # Also save to recommendations column with timestamp
        recommendations_data = user.recommendations or {}
        if not isinstance(recommendations_data, dict):
            recommendations_data = {}
        
        # Save recommendation with timestamp
        recommendations_data["last_recommendation"] = {
            "text": request.recommendation,
            "analysis_id": request.analysis_id,
            "created_at": datetime.utcnow().isoformat()
        }
        user.recommendations = recommendations_data
        flag_modified(user, "recommendations")
        
        user.updated_at = datetime.utcnow()
        
        db.commit()
        db.refresh(user)
        
        print(f"‚úÖ Recommendation saved to rekom and recommendations for user {request.tgid}")
        print(f"Analysis ID: {request.analysis_id}")
        
        return {
            "success": True,
            "message": "Recommendation saved to rekom and recommendations",
            "tgid": request.tgid,
            "analysis_id": request.analysis_id,
            "recommendation_length": len(request.recommendation)
        }
    except Exception as e:
        print(f"‚ùå Error saving recommendation: {e}")
        print(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error saving recommendation: {str(e)}"
        )


# GET /api/recommendations/{analysis_id} - Get recommendation from rekom by analysis_id
@router.get("/recommendations/{analysis_id}")
async def get_recommendation_by_id(
    analysis_id: str,
    tgid: str = Depends(get_tgid_from_header),
    db: Session = Depends(get_db)
):
    """Get recommendation from rekom by analysis_id"""
    user = queries.get_or_create_user(db, tgid)
    rekom_data = user.rekom or {}
    
    if isinstance(rekom_data, dict) and analysis_id in rekom_data:
        return {
            "analysis_id": analysis_id,
            "recommendation": rekom_data[analysis_id],
            "status": "ready"
        }
    
    return {
        "analysis_id": analysis_id,
        "status": "processing",
        "message": "Recommendation is being processed"
    }


# GET /api/recommendations/last - Get last recommendation from recommendations column
@router.get("/recommendations/last")
async def get_last_recommendation(
    tgid: str = Depends(get_tgid_from_header),
    db: Session = Depends(get_db)
):
    """Get last recommendation from recommendations column"""
    user = queries.get_or_create_user(db, tgid)
    recommendations_data = user.recommendations or {}
    
    if isinstance(recommendations_data, dict) and "last_recommendation" in recommendations_data:
        last_rec = recommendations_data["last_recommendation"]
        return {
            "recommendation": last_rec.get("text", ""),
            "analysis_id": last_rec.get("analysis_id", ""),
            "created_at": last_rec.get("created_at", ""),
            "status": "ready"
        }
    
    return {
        "status": "not_found",
        "message": "No recommendation found"
    }


# POST /api/notify-upload - Notify about file upload

@router.post("/notify-upload")

async def notify_upload(

    request: NotifyUploadRequest,

    tgid: str = Depends(get_tgid_from_header),

    db: Session = Depends(get_db)

):

    user = queries.notify_upload(db, tgid, request.fileName, request.mime, request.size)

    
    
    # Send file info to webhook

    webhook_url = settings.ANALYSIS_WEBHOOK_URL

    if webhook_url:

        try:

            webhook_payload = {

                "tgid": tgid,

                "fileName": request.fileName,

                "mime": request.mime,

                "size": request.size,

                "uploadedAt": user.updated_at.isoformat() if user.updated_at else None,

            }

            # Send to webhook asynchronously (don't block response)

            requests.post(

                webhook_url,

                json=webhook_payload,

                headers={"Content-Type": "application/json"},

                timeout=10

            )

        except Exception as e:

            # Log error but don't fail the request

            print(f"Webhook error: {e}")
    
    

    return {

        "fileName": request.fileName,

        "mime": request.mime,

        "size": request.size,

        "analyses": user.analyses or {}

    }





# Request model for analysis result (JSON)

class AnalysisResultRequest(BaseModel):

    tgid: str

    report: str

    fileName: Optional[str] = None

    clientTime: Optional[str] = None  # Client's local time (ISO format with timezone)





# POST /api/analyses/result - Receive analysis result from n8n (no auth required)

# Accepts both JSON and Form-Data for flexibility

@router.post("/analyses/result")

async def receive_analysis_result(

    raw_request: Request,

    request_data: Optional[AnalysisResultRequest] = None,

    tgid: Optional[str] = Form(None),

    report: Optional[str] = Form(None),

    fileName: Optional[str] = Form(None),

    clientTime: Optional[str] = Form(None),

    db: Session = Depends(get_db)

):

    """Receive analysis report from n8n and save to database

    
    
    Accepts both formats:

    1. JSON body: {"tgid": "...", "report": "...", "fileName": "..."}

    2. Form-Data: tgid, report, fileName as form fields

    3. Nested JSON: {"body": {"tgid": "...", "report": "..."}}

    
    
    n8n can send any of these formats.

    """

    print(f"=== Receiving analysis result from n8n ===")

    
    
    tgid_value = None

    report_value = None

    fileName_value = None

    client_time_value = None

    
    
    # Try to get data from JSON first (Pydantic model)

    if request_data:

        tgid_value = request_data.tgid

        report_value = request_data.report

        fileName_value = request_data.fileName

        client_time_value = request_data.clientTime

        print("Received as JSON (Pydantic model)")

    # Try Form-Data

    elif tgid and report:

        tgid_value = tgid

        report_value = report

        fileName_value = fileName

        client_time_value = clientTime  # Get from Form if available

        print("Received as Form-Data")

    # Try to parse raw request body (for nested JSON from n8n)

    else:

        try:

            content_type = raw_request.headers.get("content-type", "")

            if "application/json" in content_type:

                json_data = await raw_request.json()

                print(f"Raw JSON received: {list(json_data.keys()) if isinstance(json_data, dict) else 'not a dict'}")

                
                
                # Handle nested body structure from n8n: {"body": {"tgid": "...", "report": "..."}}

                if isinstance(json_data, dict):

                    if "body" in json_data and isinstance(json_data["body"], dict):

                        # n8n sometimes wraps data in "body"

                        json_data = json_data["body"]

                        print("Unwrapped nested 'body' structure")

                    tgid_value = json_data.get("tgid")

                    report_value = json_data.get("report")

                    fileName_value = json_data.get("fileName")

                    client_time_value = json_data.get("clientTime")

                    print("Received as nested JSON from raw request")

        except Exception as e:

            print(f"Error parsing raw request: {e}")

            print(traceback.format_exc())
    
    

    if not tgid_value or not report_value:

        raise HTTPException(

            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,

            detail="Missing required fields: tgid and report. Send as JSON {\"tgid\": \"...\", \"report\": \"...\"} or Form-Data."

        )
    
    

    print(f"TGID: {tgid_value}")

    print(f"Report length: {len(report_value)} characters")

    print(f"FileName: {fileName_value}")

    print(f"First 200 chars of report: {report_value[:200]}...")

    
    
    try:

        # Get or create user

        user = queries.get_or_create_user(db, tgid_value)

        
        
        # Get existing reports only (ignore last_upload, upload_history - they are not part of analyses)

        current_analyses = user.analyses or {}

        reports = current_analyses.get("reports", [])

        
        
        # Use client's local time if provided, otherwise use UTC server time
        # client_time_value comes from the webhook (n8n should return it back)
        created_at = client_time_value if client_time_value else datetime.utcnow().isoformat()
        
        if client_time_value:
            print(f"Using client's local time: {client_time_value}")
        else:
            print(f"Using UTC server time (clientTime not provided): {created_at}")
        
        # Create new report

        new_report = {

            "text": report_value,

            "fileName": fileName_value or "unknown",

            "createdAt": created_at,

        }

        
        
        # Add to reports list

        reports.append(new_report)

        
        
        # Save ONLY report data in analyses (no last_upload, upload_history)

        # analyses should contain only what comes from HTTP Request (reports)

        user.analyses = {

            "reports": reports,

            "last_report": new_report  # Save last report for quick access

        }

        
        
        # Add to allanalize - –∏—Å—Ç–æ—Ä–∏—è –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤

        # –í–ê–ñ–ù–û: –≤ allanalize —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã, –∞ –Ω–µ –≤–µ—Å—å –æ–±—ä–µ–∫—Ç analyses

        current_allanalize = user.allanalize or {}

        all_analyses_list = []

        
        
        # –ï—Å–ª–∏ allanalize - —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ

        if isinstance(current_allanalize, list):

            all_analyses_list = current_allanalize.copy()

        # –ï—Å–ª–∏ allanalize - —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º "analyses" –∏–ª–∏ "history"

        elif isinstance(current_allanalize, dict):

            if "analyses" in current_allanalize and isinstance(current_allanalize["analyses"], list):

                all_analyses_list = current_allanalize["analyses"].copy()

            elif "history" in current_allanalize and isinstance(current_allanalize["history"], list):

                all_analyses_list = current_allanalize["history"].copy()

            else:

                # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–±—ä–µ–∫—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫

                all_analyses_list = []
        
        

        # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ new_report (–æ—Ç–¥–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç), –∞ –Ω–µ –≤–µ—Å—å –æ–±—ä–µ–∫—Ç analyses

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç —É–∂–µ —Ç–∞–∫–æ–π –∂–µ (–ø–æ fileName –∏ createdAt), –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º

        if all_analyses_list:

            last_item = all_analyses_list[-1]

            if isinstance(last_item, dict):

                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç - —ç—Ç–æ –≤–µ—Å—å –æ–±—ä–µ–∫—Ç analyses (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç), —É–¥–∞–ª—è–µ–º –µ–≥–æ

                if "reports" in last_item and "last_report" in last_item:

                    # –≠—Ç–æ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - —É–¥–∞–ª—è–µ–º –µ–≥–æ

                    all_analyses_list.pop()

                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Ç–∞–∫–æ–π –∂–µ –æ—Ç—á–µ—Ç, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç

                elif last_item.get("fileName") == new_report["fileName"] and last_item.get("createdAt") == new_report["createdAt"]:

                    # –î—É–±–ª–∏–∫–∞—Ç - –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º

                    pass

                else:

                    all_analyses_list.append(new_report)

            else:

                all_analyses_list.append(new_report)

        else:

            all_analyses_list.append(new_report)
        
        

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –≤ allanalize

        user.allanalize = all_analyses_list

        
        
        # –ü–æ–º–µ—á–∞–µ–º JSONB –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ

        from sqlalchemy.orm.attributes import flag_modified

        flag_modified(user, "analyses")

        flag_modified(user, "allanalize")

        
        
        user.updated_at = datetime.utcnow()

        
        
        db.flush()

        db.commit()

        db.refresh(user)

        
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        print(f"‚úÖ Report saved successfully for user {tgid_value}")

        print(f"Analyses now contains only reports (no upload data)")

        print(f"Reports count: {len(reports)}")

        print(f"Last report exists: True")

        print(f"‚úÖ All analyses history saved to allanalize")

        print(f"All analyses count: {len(all_analyses_list)}")

        print(f"Allanalize type: {type(user.allanalize)}")

        
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å

        print(f"[DEBUG] After commit and refresh:")

        print(f"[DEBUG] user.analyses type: {type(user.analyses)}")

        print(f"[DEBUG] user.analyses value: {user.analyses}")

        if isinstance(user.analyses, dict):

            print(f"[DEBUG] user.analyses keys: {list(user.analyses.keys())}")

            if "last_report" in user.analyses:

                print(f"[DEBUG] user.analyses['last_report']: {user.analyses['last_report']}")

                if isinstance(user.analyses["last_report"], dict):

                    print(f"[DEBUG] user.analyses['last_report'] keys: {list(user.analyses['last_report'].keys())}")

                    if "text" in user.analyses["last_report"]:

                        text_val = user.analyses["last_report"]["text"]

                        print(f"[DEBUG] user.analyses['last_report']['text'] type: {type(text_val)}")

                        print(f"[DEBUG] user.analyses['last_report']['text'] length: {len(text_val) if isinstance(text_val, str) else 'not a string'}")

                        print(f"[DEBUG] user.analyses['last_report']['text'] first 200 chars: {text_val[:200] if isinstance(text_val, str) else 'not a string'}")

                    else:

                        print(f"[DEBUG] WARNING: 'text' key not found in last_report!")

                else:

                    print(f"[DEBUG] WARNING: last_report is not a dict, type: {type(user.analyses['last_report'])}")

            else:

                print(f"[DEBUG] WARNING: 'last_report' key not found in analyses!")

        else:

            print(f"[DEBUG] WARNING: user.analyses is not a dict, type: {type(user.analyses)}")
        
        

        return {

            "success": True,

            "message": "Report saved",

            "tgid": tgid_value,

            "reportLength": len(report_value),

            "analysesKeys": list(user.analyses.keys())

        }

    except Exception as e:

        print(f"‚ùå Error saving report: {e}")

        print(traceback.format_exc())

        raise HTTPException(

            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,

            detail=f"Error saving report: {str(e)}"

        )





# POST /api/upload-file - Upload file to webhook (proxy)

@router.post("/upload-file")

async def upload_file_to_webhook(

    file: UploadFile = File(...),

    fileName: str = Form(...),

    mimeType: str = Form(...),

    size: int = Form(...),

    clientTime: Optional[str] = Form(None),

    x_telegram_initdata: Optional[str] = Header(None),

    db: Session = Depends(get_db)

):

    """Proxy file upload to webhook"""

    print("=" * 50)

    print("UPLOAD FILE ENDPOINT CALLED - FUNCTION STARTED")

    print("=" * 50)

    
    
    # Get tgid from header (optional for now to debug 404)

    tgid = "unknown"

    if x_telegram_initdata:

        try:

            # Call the function directly with the header value

            tgid = get_tgid_from_header(x_telegram_initdata)

            print(f"TGID extracted from header: {tgid}")

        except Exception as auth_err:

            print(f"Auth error (continuing anyway): {auth_err}")

            print(traceback.format_exc())

            # Use a default tgid if auth fails

            tgid = "auth_failed"

    else:

        print("WARNING: No x-telegram-initdata header provided")

    print(f"Received file: {fileName}")

    print(f"File size: {size}")

    print(f"File type: {mimeType}")

    print(f"TGID: {tgid}")

    
    
    # Get user profile data from database

    profile_data = {}

    if tgid != "unknown" and tgid != "auth_failed":

        try:

            user = queries.get_or_create_user(db, tgid)

            profile_data = user.profile or {}

            print(f"Profile data loaded: {list(profile_data.keys()) if profile_data else 'empty'}")

        except Exception as profile_err:

            print(f"Warning: Could not load profile data: {profile_err}")

            profile_data = {}

    else:

        print("Skipping profile load - invalid tgid")
    
    

    webhook_url = settings.ANALYSIS_WEBHOOK_URL

    print(f"Webhook URL from settings: {webhook_url}")

    
    
    # If webhook is not configured, we'll just save to database and return success
    

    try:

        # Update database first (always do this)
        analyses = {}

        try:

            print("Updating database...")

            user = queries.notify_upload(db, tgid, fileName, mimeType, size)

            print("Database updated successfully")

            analyses = user.analyses or {}

        except Exception as db_err:

            print(f"‚ö†Ô∏è Database update failed (non-critical): {db_err}")

        
        # Send to webhook only if configured
        response = None
        
        if webhook_url:

            print("Reading file content...")

            # Read file content

            file_content = await file.read()

            print(f"File content read: {len(file_content)} bytes")

            
            
            # Extract text from PDF if it's a PDF file
            extracted_text = None
            if mimeType == "application/pdf":
                print("üìÑ PDF file detected - extracting text...")
                extracted_text = extract_text_from_pdf(file_content)
                if extracted_text:
                    print(f"‚úÖ Extracted {len(extracted_text)} characters from PDF")
                else:
                    print("‚ö†Ô∏è Warning: Could not extract text from PDF, will send file as-is")
            
            
            print(f"=== Sending file to webhook ===")

            print(f"Webhook URL: {webhook_url}")

            print(f"File: {fileName}, Size: {size} bytes, Type: {mimeType}, TGID: {tgid}")

            
            
            # Encode file to base64

            import base64

            print("Encoding file to base64...")

            file_base64 = base64.b64encode(file_content).decode('utf-8')

            print(f"File encoded to base64: {len(file_base64)} characters")

            
            
            # Build JSON payload with base64 file and profile data for n8n

            json_data = {

                'fileName': fileName,

                'mimeType': mimeType,

                'size': size,

                'tgid': tgid,

                'file': file_base64,  # Base64 encoded file (image or PDF)

                'profile': profile_data,  # User profile data from database

                'clientTime': clientTime,  # Client's local time (ISO format with timezone)

            }

            # Add extracted text if PDF
            if extracted_text:
                json_data['extractedText'] = extracted_text
                print(f"‚úÖ Added extracted text to payload ({len(extracted_text)} characters)")

            
            
            print(f"Building JSON payload for n8n...")

            print(f"JSON keys: {list(json_data.keys())}")

            print(f"JSON size: {len(str(json_data))} characters")

            print(f"Base64 data length: {len(file_base64)} characters")
            if extracted_text:
                print(f"Extracted text length: {len(extracted_text)} characters")
            print(f"Profile data keys: {list(profile_data.keys()) if profile_data else 'none'}")

            print(f"First 100 chars of base64: {file_base64[:100]}...")

            
            
            # Send to n8n webhook

            # IMPORTANT: n8n webhooks should be configured to accept POST, not GET

            # GET requests cannot send file data (URL length limit)

            print(f"Sending POST request with JSON to n8n webhook: {webhook_url}")

            payload_description = "fileName, mimeType, size, tgid, file (base64), profile"
            if extracted_text:
                payload_description += ", extractedText"
            print(f"Payload contains: {payload_description}")

            print(f"Total payload size: {len(str(json_data))} characters")
            
            
            
            try:

                response = requests.post(

                    webhook_url,

                    json=json_data,

                    headers={

                        'Content-Type': 'application/json',

                    },

                    timeout=60,

                    allow_redirects=True

                )

                
                
                print(f"‚úÖ Request sent successfully! Response status: {response.status_code}")

                print(f"Webhook response headers: {dict(response.headers)}")

                response_text = response.text[:500] if response.text else 'No response'

                print(f"Webhook response (first 500 chars): {response_text}")

                
                
                # Log response status

                if response.status_code == 404:

                    print(f"‚ö†Ô∏è WARNING: Webhook returned 404. Check n8n webhook settings - it should accept POST requests.")

                elif response.status_code >= 400:

                    print(f"‚ö†Ô∏è WARNING: Webhook returned {response.status_code}. Check n8n webhook configuration.")

                else:

                    print(f"‚úÖ SUCCESS: Webhook accepted request (status {response.status_code})")
                    
                    

            except Exception as send_err:

                print(f"‚ùå ERROR sending to webhook: {send_err}")

                print(traceback.format_exc())

                # Don't fail - we tried to send

                response = type('obj', (object,), {'status_code': 0, 'text': str(send_err)})()

        else:

            print("‚ö†Ô∏è Webhook URL not configured - skipping webhook call, file saved to database only")

            response = type('obj', (object,), {'status_code': None, 'text': 'Webhook not configured'})()

        
        

        # Always return success from our side

        result = {

            "success": True,

            "message": "File sent to n8n webhook" if webhook_url else "File saved to database",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": response.status_code if response else None,

            "webhookResponse": response.text[:1000] if response and response.text else None,

            "analyses": analyses

        }

        print(f"‚úÖ Returning success result")

        print("=" * 50)

        print("UPLOAD FILE ENDPOINT - SUCCESS")

        print("=" * 50)

        return result

    except requests.exceptions.Timeout as e:

        print(f"Webhook timeout error: {e}")

        # Update database even on timeout (file was processed)

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the timeout

        return {

            "success": True,

            "message": "File sent to webhook (timeout waiting for response)",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "timeout",

            "webhookResponse": None,

            "analyses": user.analyses or {}

        }

    except requests.exceptions.ConnectionError as e:

        print(f"Webhook connection error: {e}")

        # Update database

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the connection error

        return {

            "success": True,

            "message": "File sent to webhook (connection error)",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "connection_error",

            "webhookResponse": str(e),

            "analyses": user.analyses or {}

        }

    except requests.exceptions.RequestException as e:

        print(f"Webhook request error: {e}")

        import traceback

        print(traceback.format_exc())

        # Update database

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the error

        return {

            "success": True,

            "message": f"File sent to webhook (error: {str(e)})",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "error",

            "webhookResponse": str(e),

            "analyses": user.analyses or {}

        }

    except Exception as e:

        print(f"Upload error: {e}")

        import traceback

        print(traceback.format_exc())

        # Don't fail completely - still try to update database

        try:

            user = queries.notify_upload(db, tgid, fileName, mimeType, size)

            analyses = user.analyses or {}

        except:

            analyses = {}
        
        

        # Return error but with details

        raise HTTPException(

            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,

            detail=f"Upload error: {str(e)}"

        )




        current_allanalize = user.allanalize or {}

        all_analyses_list = []

        

        # –ï—Å–ª–∏ allanalize - —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ

        if isinstance(current_allanalize, list):

            all_analyses_list = current_allanalize.copy()

        # –ï—Å–ª–∏ allanalize - —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º "analyses" –∏–ª–∏ "history"

        elif isinstance(current_allanalize, dict):

            if "analyses" in current_allanalize and isinstance(current_allanalize["analyses"], list):

                all_analyses_list = current_allanalize["analyses"].copy()

            elif "history" in current_allanalize and isinstance(current_allanalize["history"], list):

                all_analyses_list = current_allanalize["history"].copy()

            else:

                # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–±—ä–µ–∫—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫

                all_analyses_list = []

        

        # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ new_report (–æ—Ç–¥–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç), –∞ –Ω–µ –≤–µ—Å—å –æ–±—ä–µ–∫—Ç analyses

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç —É–∂–µ —Ç–∞–∫–æ–π –∂–µ (–ø–æ fileName –∏ createdAt), –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º

        if all_analyses_list:

            last_item = all_analyses_list[-1]

            if isinstance(last_item, dict):

                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç - —ç—Ç–æ –≤–µ—Å—å –æ–±—ä–µ–∫—Ç analyses (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç), —É–¥–∞–ª—è–µ–º –µ–≥–æ

                if "reports" in last_item and "last_report" in last_item:

                    # –≠—Ç–æ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - —É–¥–∞–ª—è–µ–º –µ–≥–æ

                    all_analyses_list.pop()

                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Ç–∞–∫–æ–π –∂–µ –æ—Ç—á–µ—Ç, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç

                elif last_item.get("fileName") == new_report["fileName"] and last_item.get("createdAt") == new_report["createdAt"]:

                    # –î—É–±–ª–∏–∫–∞—Ç - –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º

                    pass

                else:

                    all_analyses_list.append(new_report)

            else:

                all_analyses_list.append(new_report)

        else:

            all_analyses_list.append(new_report)

        

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –≤ allanalize

        user.allanalize = all_analyses_list

        

        # –ü–æ–º–µ—á–∞–µ–º JSONB –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ

        from sqlalchemy.orm.attributes import flag_modified

        flag_modified(user, "analyses")

        flag_modified(user, "allanalize")

        

        user.updated_at = datetime.utcnow()

        

        db.flush()

        db.commit()

        db.refresh(user)

        

        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        print(f"‚úÖ Report saved successfully for user {tgid_value}")

        print(f"Analyses now contains only reports (no upload data)")

        print(f"Reports count: {len(reports)}")

        print(f"Last report exists: True")

        print(f"‚úÖ All analyses history saved to allanalize")

        print(f"All analyses count: {len(all_analyses_list)}")

        print(f"Allanalize type: {type(user.allanalize)}")

        

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å

        print(f"[DEBUG] After commit and refresh:")

        print(f"[DEBUG] user.analyses type: {type(user.analyses)}")

        print(f"[DEBUG] user.analyses value: {user.analyses}")

        if isinstance(user.analyses, dict):

            print(f"[DEBUG] user.analyses keys: {list(user.analyses.keys())}")

            if "last_report" in user.analyses:

                print(f"[DEBUG] user.analyses['last_report']: {user.analyses['last_report']}")

                if isinstance(user.analyses["last_report"], dict):

                    print(f"[DEBUG] user.analyses['last_report'] keys: {list(user.analyses['last_report'].keys())}")

                    if "text" in user.analyses["last_report"]:

                        text_val = user.analyses["last_report"]["text"]

                        print(f"[DEBUG] user.analyses['last_report']['text'] type: {type(text_val)}")

                        print(f"[DEBUG] user.analyses['last_report']['text'] length: {len(text_val) if isinstance(text_val, str) else 'not a string'}")

                        print(f"[DEBUG] user.analyses['last_report']['text'] first 200 chars: {text_val[:200] if isinstance(text_val, str) else 'not a string'}")

                    else:

                        print(f"[DEBUG] WARNING: 'text' key not found in last_report!")

                else:

                    print(f"[DEBUG] WARNING: last_report is not a dict, type: {type(user.analyses['last_report'])}")

            else:

                print(f"[DEBUG] WARNING: 'last_report' key not found in analyses!")

        else:

            print(f"[DEBUG] WARNING: user.analyses is not a dict, type: {type(user.analyses)}")

        

        return {

            "success": True,

            "message": "Report saved",

            "tgid": tgid_value,

            "reportLength": len(report_value),

            "analysesKeys": list(user.analyses.keys())

        }

    except Exception as e:

        print(f"‚ùå Error saving report: {e}")

        print(traceback.format_exc())

        raise HTTPException(

            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,

            detail=f"Error saving report: {str(e)}"

        )





# POST /api/upload-file - Upload file to webhook (proxy)

@router.post("/upload-file")

async def upload_file_to_webhook(

    file: UploadFile = File(...),

    fileName: str = Form(...),

    mimeType: str = Form(...),

    size: int = Form(...),

    clientTime: Optional[str] = Form(None),

    x_telegram_initdata: Optional[str] = Header(None),

    db: Session = Depends(get_db)

):

    """Proxy file upload to webhook"""

    print("=" * 50)

    print("UPLOAD FILE ENDPOINT CALLED - FUNCTION STARTED")

    print("=" * 50)

    

    # Get tgid from header (optional for now to debug 404)

    tgid = "unknown"

    if x_telegram_initdata:

        try:

            # Call the function directly with the header value

            tgid = get_tgid_from_header(x_telegram_initdata)

            print(f"TGID extracted from header: {tgid}")

        except Exception as auth_err:

            print(f"Auth error (continuing anyway): {auth_err}")

            print(traceback.format_exc())

            # Use a default tgid if auth fails

            tgid = "auth_failed"

    else:

        print("WARNING: No x-telegram-initdata header provided")

    print(f"Received file: {fileName}")

    print(f"File size: {size}")

    print(f"File type: {mimeType}")

    print(f"TGID: {tgid}")

    

    # Get user profile data from database

    profile_data = {}

    if tgid != "unknown" and tgid != "auth_failed":

        try:

            user = queries.get_or_create_user(db, tgid)

            profile_data = user.profile or {}

            print(f"Profile data loaded: {list(profile_data.keys()) if profile_data else 'empty'}")

        except Exception as profile_err:

            print(f"Warning: Could not load profile data: {profile_err}")

            profile_data = {}

    else:

        print("Skipping profile load - invalid tgid")

    

    webhook_url = settings.ANALYSIS_WEBHOOK_URL

    print(f"Webhook URL from settings: {webhook_url}")

    

    # If webhook is not configured, we'll just save to database and return success
    

    try:

        # Update database first (always do this)
        analyses = {}

        try:

            print("Updating database...")

            user = queries.notify_upload(db, tgid, fileName, mimeType, size)

            print("Database updated successfully")

            analyses = user.analyses or {}

        except Exception as db_err:

            print(f"‚ö†Ô∏è Database update failed (non-critical): {db_err}")

        
        # Send to webhook only if configured
        response = None
        
        if webhook_url:

            print("Reading file content...")

            # Read file content

            file_content = await file.read()

            print(f"File content read: {len(file_content)} bytes")

            
            
            # Extract text from PDF if it's a PDF file
            extracted_text = None
            if mimeType == "application/pdf":
                print("üìÑ PDF file detected - extracting text...")
                extracted_text = extract_text_from_pdf(file_content)
                if extracted_text:
                    print(f"‚úÖ Extracted {len(extracted_text)} characters from PDF")
                else:
                    print("‚ö†Ô∏è Warning: Could not extract text from PDF, will send file as-is")
            

            print(f"=== Sending file to webhook ===")

            print(f"Webhook URL: {webhook_url}")

            print(f"File: {fileName}, Size: {size} bytes, Type: {mimeType}, TGID: {tgid}")

            

            # Encode file to base64

            import base64

            print("Encoding file to base64...")

            file_base64 = base64.b64encode(file_content).decode('utf-8')

            print(f"File encoded to base64: {len(file_base64)} characters")

            

            # Build JSON payload with base64 file and profile data for n8n

            json_data = {

                'fileName': fileName,

                'mimeType': mimeType,

                'size': size,

                'tgid': tgid,

                'file': file_base64,  # Base64 encoded file (image or PDF)

                'profile': profile_data,  # User profile data from database

                'clientTime': clientTime,  # Client's local time (ISO format with timezone)

            }

            # Add extracted text if PDF
            if extracted_text:
                json_data['extractedText'] = extracted_text
                print(f"‚úÖ Added extracted text to payload ({len(extracted_text)} characters)")

            

            print(f"Building JSON payload for n8n...")

            print(f"JSON keys: {list(json_data.keys())}")

            print(f"JSON size: {len(str(json_data))} characters")

            print(f"Base64 data length: {len(file_base64)} characters")
            if extracted_text:
                print(f"Extracted text length: {len(extracted_text)} characters")
            print(f"Profile data keys: {list(profile_data.keys()) if profile_data else 'none'}")

            print(f"First 100 chars of base64: {file_base64[:100]}...")

            

            # Send to n8n webhook

            # IMPORTANT: n8n webhooks should be configured to accept POST, not GET

            # GET requests cannot send file data (URL length limit)

            print(f"Sending POST request with JSON to n8n webhook: {webhook_url}")

            payload_description = "fileName, mimeType, size, tgid, file (base64), profile"
            if extracted_text:
                payload_description += ", extractedText"
            print(f"Payload contains: {payload_description}")

            print(f"Total payload size: {len(str(json_data))} characters")

            

            try:

                response = requests.post(

                    webhook_url,

                    json=json_data,

                    headers={

                        'Content-Type': 'application/json',

                    },

                    timeout=60,

                    allow_redirects=True

                )

                

                print(f"‚úÖ Request sent successfully! Response status: {response.status_code}")

                print(f"Webhook response headers: {dict(response.headers)}")

                response_text = response.text[:500] if response.text else 'No response'

                print(f"Webhook response (first 500 chars): {response_text}")

                

                # Log response status

                if response.status_code == 404:

                    print(f"‚ö†Ô∏è WARNING: Webhook returned 404. Check n8n webhook settings - it should accept POST requests.")

                elif response.status_code >= 400:

                    print(f"‚ö†Ô∏è WARNING: Webhook returned {response.status_code}. Check n8n webhook configuration.")

                else:

                    print(f"‚úÖ SUCCESS: Webhook accepted request (status {response.status_code})")

                    

            except Exception as send_err:

                print(f"‚ùå ERROR sending to webhook: {send_err}")

                print(traceback.format_exc())

                # Don't fail - we tried to send

                response = type('obj', (object,), {'status_code': 0, 'text': str(send_err)})()

        else:

            print("‚ö†Ô∏è Webhook URL not configured - skipping webhook call, file saved to database only")

            response = type('obj', (object,), {'status_code': None, 'text': 'Webhook not configured'})()

        

        # Always return success from our side

        result = {

            "success": True,

            "message": "File sent to n8n webhook" if webhook_url else "File saved to database",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": response.status_code if response else None,

            "webhookResponse": response.text[:1000] if response and response.text else None,

            "analyses": analyses

        }

        print(f"‚úÖ Returning success result")

        print("=" * 50)

        print("UPLOAD FILE ENDPOINT - SUCCESS")

        print("=" * 50)

        return result

    except requests.exceptions.Timeout as e:

        print(f"Webhook timeout error: {e}")

        # Update database even on timeout (file was processed)

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the timeout

        return {

            "success": True,

            "message": "File sent to webhook (timeout waiting for response)",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "timeout",

            "webhookResponse": None,

            "analyses": user.analyses or {}

        }

    except requests.exceptions.ConnectionError as e:

        print(f"Webhook connection error: {e}")

        # Update database

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the connection error

        return {

            "success": True,

            "message": "File sent to webhook (connection error)",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "connection_error",

            "webhookResponse": str(e),

            "analyses": user.analyses or {}

        }

    except requests.exceptions.RequestException as e:

        print(f"Webhook request error: {e}")

        import traceback

        print(traceback.format_exc())

        # Update database

        user = queries.notify_upload(db, tgid, fileName, mimeType, size)

        # Return success but note the error

        return {

            "success": True,

            "message": f"File sent to webhook (error: {str(e)})",

            "fileName": fileName,

            "mime": mimeType,

            "size": size,

            "webhookStatus": "error",

            "webhookResponse": str(e),

            "analyses": user.analyses or {}

        }

    except Exception as e:

        print(f"Upload error: {e}")

        import traceback

        print(traceback.format_exc())

        # Don't fail completely - still try to update database

        try:

            user = queries.notify_upload(db, tgid, fileName, mimeType, size)

            analyses = user.analyses or {}

        except:

            analyses = {}

        

        # Return error but with details

        raise HTTPException(

            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,

            detail=f"Upload error: {str(e)}"

        )




